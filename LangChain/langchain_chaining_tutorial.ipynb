{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangChain Chaining Tutorial\n",
        "\n",
        "This notebook demonstrates various chaining techniques in LangChain including:\n",
        "- Simple Sequential Chains\n",
        "- Sequential Chains with Multiple Inputs/Outputs\n",
        "- Router Chains\n",
        "- LCEL (LangChain Expression Language)\n",
        "\n",
        "## Prerequisites\n",
        "```bash\n",
        "pip install langchain langchain-openai langchain-community\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "# Set your API key\n",
        "os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Simple Sequential Chain\n",
        "\n",
        "The simplest form of chaining where output of one chain becomes input of the next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chain 1: Generate a product name\n",
        "first_prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\"\n",
        ")\n",
        "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
        "\n",
        "# Chain 2: Generate a tagline for the company\n",
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"company_name\"],\n",
        "    template=\"Write a catchy tagline for the following company: {company_name}\"\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
        "\n",
        "# Combine chains\n",
        "simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
        "\n",
        "# Run the chain\n",
        "result = simple_chain.run(\"eco-friendly water bottles\")\n",
        "print(f\"\\nFinal Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sequential Chain with Multiple Inputs/Outputs\n",
        "\n",
        "More complex chains that can handle multiple variables across steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chain 1: Generate a synopsis\n",
        "synopsis_template = \"\"\"You are a playwright. Given the title and era of a play,\n",
        "write a synopsis for that play.\n",
        "\n",
        "Title: {title}\n",
        "Era: {era}\n",
        "Synopsis:\"\"\"\n",
        "synopsis_prompt = PromptTemplate(input_variables=[\"title\", \"era\"], template=synopsis_template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=synopsis_prompt, output_key=\"synopsis\")\n",
        "\n",
        "# Chain 2: Write a review based on synopsis\n",
        "review_template = \"\"\"You are a theater critic. Given the synopsis of a play,\n",
        "write a review for that play.\n",
        "\n",
        "Synopsis:\n",
        "{synopsis}\n",
        "\n",
        "Review:\"\"\"\n",
        "review_prompt = PromptTemplate(input_variables=[\"synopsis\"], template=review_template)\n",
        "review_chain = LLMChain(llm=llm, prompt=review_prompt, output_key=\"review\")\n",
        "\n",
        "# Combine chains\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[synopsis_chain, review_chain],\n",
        "    input_variables=[\"title\", \"era\"],\n",
        "    output_variables=[\"synopsis\", \"review\"],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "result = overall_chain({\"title\": \"The AI Revolution\", \"era\": \"2024\"})\n",
        "print(f\"\\nSynopsis:\\n{result['synopsis']}\")\n",
        "print(f\"\\nReview:\\n{result['review']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Router Chain\n",
        "\n",
        "Routes inputs to different chains based on content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
        "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
        "\n",
        "# Define destination chains\n",
        "physics_template = \"\"\"You are a physics professor. Explain the following concept:\n",
        "{input}\"\"\"\n",
        "\n",
        "math_template = \"\"\"You are a math professor. Solve the following problem:\n",
        "{input}\"\"\"\n",
        "\n",
        "history_template = \"\"\"You are a history professor. Explain the following historical event:\n",
        "{input}\"\"\"\n",
        "\n",
        "# Create prompt infos\n",
        "prompt_infos = [\n",
        "    {\"name\": \"physics\", \"description\": \"Good for physics questions\", \"prompt_template\": physics_template},\n",
        "    {\"name\": \"math\", \"description\": \"Good for math problems\", \"prompt_template\": math_template},\n",
        "    {\"name\": \"history\", \"description\": \"Good for history questions\", \"prompt_template\": history_template}\n",
        "]\n",
        "\n",
        "# Create destination chains\n",
        "destination_chains = {}\n",
        "for p_info in prompt_infos:\n",
        "    name = p_info[\"name\"]\n",
        "    prompt = PromptTemplate(template=p_info[\"prompt_template\"], input_variables=[\"input\"])\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    destination_chains[name] = chain\n",
        "\n",
        "# Create default chain\n",
        "default_chain = LLMChain(llm=llm, prompt=PromptTemplate(\n",
        "    template=\"{input}\",\n",
        "    input_variables=[\"input\"]\n",
        "))\n",
        "\n",
        "# Create router chain\n",
        "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
        "destinations_str = \"\\n\".join(destinations)\n",
        "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
        "router_prompt = PromptTemplate(\n",
        "    template=router_template,\n",
        "    input_variables=[\"input\"],\n",
        "    output_parser=RouterOutputParser()\n",
        ")\n",
        "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
        "\n",
        "# Create multi-prompt chain\n",
        "chain = MultiPromptChain(\n",
        "    router_chain=router_chain,\n",
        "    destination_chains=destination_chains,\n",
        "    default_chain=default_chain,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Test with different inputs\n",
        "print(chain.run(\"What is Newton's second law?\"))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(chain.run(\"Solve: 2x + 5 = 15\"))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(chain.run(\"What caused World War I?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LCEL (LangChain Expression Language)\n",
        "\n",
        "Modern way of chaining using pipes (|) - more Pythonic and flexible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Create a simple LCEL chain\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Tell me a joke about {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "# Chain using LCEL\n",
        "lcel_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain\n",
        "result = lcel_chain.invoke({\"topic\": \"AI\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Advanced LCEL - Multi-step Chain\n",
        "\n",
        "Building complex chains with LCEL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Generate topic\n",
        "topic_prompt = PromptTemplate(\n",
        "    template=\"Generate a random {subject} topic\",\n",
        "    input_variables=[\"subject\"]\n",
        ")\n",
        "\n",
        "# Step 2: Create content about topic\n",
        "content_prompt = PromptTemplate(\n",
        "    template=\"Write a brief paragraph about: {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "# Step 3: Summarize content\n",
        "summary_prompt = PromptTemplate(\n",
        "    template=\"Summarize this in one sentence: {content}\",\n",
        "    input_variables=[\"content\"]\n",
        ")\n",
        "\n",
        "# Build the chain\n",
        "advanced_chain = (\n",
        "    {\"subject\": RunnablePassthrough()}\n",
        "    | topic_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "    | {\"topic\": RunnablePassthrough()}\n",
        "    | content_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "    | {\"content\": RunnablePassthrough()}\n",
        "    | summary_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "result = advanced_chain.invoke(\"technology\")\n",
        "print(f\"Final Summary: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Parallel Chains with LCEL\n",
        "\n",
        "Running multiple chains in parallel and combining results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# Define multiple prompts\n",
        "pros_prompt = PromptTemplate(\n",
        "    template=\"List 3 pros of {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "cons_prompt = PromptTemplate(\n",
        "    template=\"List 3 cons of {topic}\",\n",
        "    input_variables=[\"topic\"]\n",
        ")\n",
        "\n",
        "# Create parallel chains\n",
        "parallel_chain = RunnableParallel(\n",
        "    pros=pros_prompt | llm | StrOutputParser(),\n",
        "    cons=cons_prompt | llm | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Run parallel chains\n",
        "result = parallel_chain.invoke({\"topic\": \"remote work\"})\n",
        "print(f\"Pros:\\n{result['pros']}\\n\")\n",
        "print(f\"Cons:\\n{result['cons']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook covered:\n",
        "- **SimpleSequentialChain**: Single input/output chaining\n",
        "- **SequentialChain**: Multiple inputs/outputs across steps\n",
        "- **Router Chain**: Dynamic routing based on input\n",
        "- **LCEL**: Modern, Pythonic chaining with pipes\n",
        "- **Parallel Execution**: Running chains simultaneously\n",
        "\n",
        "LCEL is now the recommended approach for building chains in LangChain due to its flexibility and ease of use."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
